data:
  dataset_name: zjotero/sampled_math_cot
  enable_thinking: false
  split: train

model:
  model_name_or_path: zjotero/Qwen2.5-1.5B-Base
  tokenizer_name_or_path: zjotero/Qwen2.5-1.5B-Base
  attn_implementation: flash_attention_2
  dtype: bfloat16
  revision: null

train:
  bf16: true
  output_dir: /home/user/ihwon/kongbu/outputs/sft_cot
  max_length: 18000
  num_train_epochs: 3
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  max_grad_norm: 1.0
  learning_rate: 5.0e-05
  logging_steps: 1
  lr_scheduler_type: cosine
  remove_unused_columns: false
  save_strategy: steps
  save_steps: 100
  save_total_limit: 10000
  seed: 92
  warmup_ratio: 0.1
  project: kongbu
  run_name: sft_cot
  report_to: wandb

hydra:
  run:
    dir: ${train.output_dir}
  sweep:
    dir: ${train.output_dir}/multirun
    subdir: ${hydra.job.num}
