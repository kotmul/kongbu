data:
  dataset_name: zjotero/sampled_math_cot
  split: train

model:
  model_name_or_path: zjotero/Qwen2.5-1.5B-Base
  tokenizer_name_or_path: zjotero/Qwen2.5-1.5B-Base
  attn_implementation: flash_attention_2
  dtype: bfloat16
  revision: null

  teacher_model_name_or_path: zjotero/Qwen3-8B
  teacher_model_init_kwargs:
    dtype: bfloat16

train:
  bf16: true
  output_dir: /home/user/ihwon/kongbu/outputs/opkd
  max_length: 18000
  num_train_epochs: 3
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  learning_rate: 5.0e-05
  logging_steps: 1
  lr_scheduler_type: cosine
  remove_unused_columns: true
  save_strategy: "epoch"
  save_total_limit: 15
  seed: 92
  warmup_ratio: 0.1
  run_name: onpolicy-test
  report_to: wandb
  project: onpolicy-cot
  # For KD
  beta: 1
  # For Onpolicy
  temperature: 0.6
  torch_empty_cache_steps: 1
  max_new_tokens: 4000
  use_vllm: true
  vllm_mode: server
  # vllm_gpu_memory_utilization: 0.55
  # vllm_tensor_parallel_size: 4
  enable_thinking: false
  save_completions_steps: 1

hydra:
  run:
    dir: ${train.output_dir}
  sweep:
    dir: ${train.output_dir}/multirun
    subdir: ${hydra.job.num}
